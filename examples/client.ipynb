{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34f8c48-90fc-4981-8d2b-b47724c2a6dd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Client Examples\n",
    "\n",
    "Client provides a uniform interface for interacting with LLMs from various providers. It adapts the official python libraries from providers such as Mistral, OpenAI, Groq, Anthropic, Fireworks, Replicate, etc. to conform to the OpenAI chat completion interface.\n",
    "\n",
    "Below are some examples of how to use Client to interact with different LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:30:02.064319Z",
     "start_time": "2024-07-04T15:30:02.051986Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "sys.path.append('../../aisuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75736ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def configure_environment(additional_env_vars=None):\n",
    "    \"\"\"\n",
    "    Load environment variables from .env file and apply any additional variables.\n",
    "    :param additional_env_vars: A dictionary of additional environment variables to apply.\n",
    "    \"\"\"\n",
    "    # Load from .env file if available\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "    # Apply additional environment variables\n",
    "    if additional_env_vars:\n",
    "        for key, value in additional_env_vars.items():\n",
    "            os.environ[key] = value\n",
    "\n",
    "# Define additional API keys and AWS credentials\n",
    "additional_keys = {\n",
    "    'GROQ_API_KEY': 'xxx',\n",
    "    'FIREWORKS_API_KEY': 'xxx', \n",
    "    'REPLICATE_API_KEY': 'xxx', \n",
    "    'TOGETHER_API_KEY': 'xxx', \n",
    "    'OCTO_API_KEY': 'xxx',\n",
    "    'AWS_ACCESS_KEY_ID': 'xxx',\n",
    "    'AWS_SECRET_ACCESS_KEY': 'xxx',\n",
    "}\n",
    "\n",
    "# Configure environment\n",
    "configure_environment(additional_env_vars=additional_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"AWS_SECRET_ACCESS_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de3a24f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:31:12.914321Z",
     "start_time": "2024-07-04T15:31:12.796445Z"
    }
   },
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "\n",
    "client = ai.Client()\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke about Captain Jack Sparrow\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "anthropic_claude_3_opus = \"anthropic:claude-3-5-sonnet-20240620\"\n",
    "response = client.chat.completions.create(model=anthropic_claude_3_opus, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893c7e4-799a-42c9-84de-f9e643044462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "# print(os.environ['AWS_ACCESS_KEY_ID'])\n",
    "# print(os.environ['AWS_REGION'])\n",
    "aws_bedrock_llama3_8b = \"aws-bedrock:meta.llama3-1-8b-instruct-v1:0\"\n",
    "response = client.chat.completions.create(model=aws_bedrock_llama3_8b, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e46c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<aisuite.framework.chat_completion_response.ChatCompletionResponse object at 0x10944bdd0>\n",
      "Arrr, listen close me hearties! Here be a joke for ye:\n",
      "\n",
      "Why did Captain Jack Sparrow go to the doctor?\n",
      "\n",
      "Because he had a bit o' a \"crabby\" day! (get it? crabby? like a crustacean, but also feeling grumpy? Ah, never mind, matey, ye landlubbers wouldn't understand...\n"
     ]
    }
   ],
   "source": [
    "client2 = ai.Client({\"azure\" : {\n",
    "  \"api_key\": os.environ[\"AZURE_API_KEY\"],\n",
    "}});\n",
    "azure_model = \"azure:aisuite-Meta-Llama-3-8B-Inst\"\n",
    "response = client2.chat.completions.create(model=azure_model, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388efc4-3fd2-4dc6-ab58-7b179ce07943",
   "metadata": {},
   "outputs": [],
   "source": [
    "octo_llama3_8b = \"octo:meta-llama-3-8b-instruct\"\n",
    "#octo_llama3_70b = \"octo:meta-llama-3-70b-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(model=octo_llama3_8b, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e6c41-070d-4041-9ed9-c8977790fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_llama3_8b = \"together:meta-llama/Llama-3-8b-chat-hf\"\n",
    "#together_llama3_70b = \"together:meta-llama/Llama-3-70b-chat-hf\"\n",
    "\n",
    "response = client.chat.completions.create(model=together_llama3_8b, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a6cfa-9011-480a-ae1b-6dbd6a51e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fireworks-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900fdf3-a113-40fd-b42f-0e6d866838be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fireworks_llama3_8b = \"fireworks:accounts/fireworks/models/llama-v3-8b-instruct\"\n",
    "#fireworks_llama3_70b = \"fireworks:accounts/fireworks/models/llama-v3-70b-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(model=fireworks_llama3_8b, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2aad6-8603-4227-9566-778f714eb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llama3_8b = \"groq:llama3-8b-8192\"\n",
    "# groq_llama3_70b = \"groq:llama3-70b-8192\"\n",
    "\n",
    "response = client.chat.completions.create(model=groq_llama3_8b, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf88b8-2ecb-4bdf-9263-4af949668d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_llama3_8b = \"replicate:meta/meta-llama-3-8b-instruct\"\n",
    "#replicate_llama3_70b = \"replicate:meta/meta-llama-3-70b-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(model=replicate_llama3_8b, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_llama3 = \"ollama:llama3\"\n",
    "\n",
    "response = client.chat.completions.create(model=ollama_llama3, messages=messages, temperature=0.75)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94961b2bddedbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:31:39.472675Z",
     "start_time": "2024-07-04T15:31:38.283368Z"
    }
   },
   "outputs": [],
   "source": [
    "mistral_7b = \"mistral:open-mistral-7b\"\n",
    "\n",
    "response = client.chat.completions.create(model=mistral_7b, messages=messages, temperature=0.2)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611210a4dc92845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_gpt35 = \"openai:gpt-3.5-turbo\"\n",
    "\n",
    "response = client.chat.completions.create(model=openai_gpt35, messages=messages, temperature=0.75)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
