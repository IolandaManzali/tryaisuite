{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary goal of this notebook is to demonstrate how to use the `aisuite` library to perform sentiment analysis using Anthropics' `Claude` model. By providing a standardized interface, `aisuite` simplifies interaction with multiple large language model (LLM) providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Anthropics library\n",
    "# This library is required for interacting with the Anthropics API.\n",
    "\n",
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section imports the necessary libraries (`anthropic`, `os`) and sets up the required environment variables to authenticate with the Anthropics API. The API key ensures secure communication with the provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30.1\n"
     ]
    }
   ],
   "source": [
    "# Import the Anthropics library and verify the installation\n",
    "import anthropic\n",
    "\n",
    "# Print the version of the installed Anthropics library\n",
    "print(anthropic.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your_api_key_here\n"
     ]
    }
   ],
   "source": [
    "# Import the os module for setting environment variables\n",
    "import os\n",
    "\n",
    "# Set the API key for Anthropics as an environment variable\n",
    "# Replace \"your_api_key_here\" with your actual API key from Anthropics\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your_api_key_here\"\n",
    "\n",
    "# Verify that the API key has been set successfully\n",
    "print(os.getenv(\"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Initialization and Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section initializes the `aisuite` client and defines the LLM model to be used for sentiment analysis. The model identifier is structured as `<provider>:<model-name>`, following the conventions mentioned in the repository documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the aisuite library for unified interaction with multiple LLM providers\n",
    "import aisuite as ai\n",
    "\n",
    "\n",
    "# Initialize the aisuite client\n",
    "# This client will be used to interact with the LLMs\n",
    "client = ai.Client()\n",
    "\n",
    "\n",
    "# Define the model to be used\n",
    "# In this case, we are using \"anthropic:claude-3-5-sonnet-20240620\"\n",
    "models = [\"anthropic:claude-3-5-sonnet-20240620\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "* `aisuite` provides a unified interface to interact with multiple LLM providers.\n",
    "* The `models` list can be extended to include other models or providers for future tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Input Text and Message Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the input text for sentiment analysis is defined, along with the message prompts for the LLM. The `system` message provides task-specific context (sentiment analysis), while the `user` message specifies the text to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text for sentiment analysis\n",
    "text = \"I like fast food\"\n",
    "\n",
    "# Define the messages for the LLM\n",
    "# The system message instructs the model on its task (sentiment analysis).\n",
    "# The user message provides the specific text to analyze and asks for a response.\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are trained to analyze and detect the sentiment of given text.\n",
    "                                    If you're unsure of an answer, you can say 'not sure' and recommend users to review manually.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"Analyze the following text and determine if the sentiment is: positive or negative.\n",
    "                                    Return answer in single word as either positive or negative: {text}\"\"\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Purpose:\n",
    "\n",
    "* Prompts are designed to maximize clarity for the model, ensuring reliable and interpretable outputs.\n",
    "* The `system` message establishes the role of the AI as a sentiment analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction with the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section processes the input text by interacting with the specified model using the `aisuite` library. The response is parsed and printed as a sentiment result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like fast food : The Sentiment is positive\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the models and get sentiment analysis responses\n",
    "# The loop ensures extensibility if more models are added in the future\n",
    "for model in models:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.75\n",
    "    )\n",
    "    # Accessing the content of the response properly from the Message object and print the sentiment \n",
    "    print(text, \": The Sentiment is\", response.choices[0].message.content.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "\n",
    "* The `create()` method sends the chat completion request to the model and retrieves the response.\n",
    "* A loop ensures scalability, allowing easy addition of new models for comparison.\n",
    "* The sentiment is extracted, processed, and displayed in a user-friendly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Handling & Extensibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```Error Handling```: Add try-except blocks around API calls to handle issues such as network errors or invalid API keys.\n",
    "* ```Extensibility```: Easily add new models or LLM providers to the models list without altering the logic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
